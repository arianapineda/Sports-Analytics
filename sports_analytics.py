"""
Sports Analytics
"""

import numeric
import codeskulptor
from urllib import request
import comp140_module6 as sports

def read_matrix(filename):
    """
    Parse data from the file with the given filename into a matrix.

    input:
        - filename: a string representing the name of the file

    returns: a matrix containing the elements in the given file
    """
    
    url = codeskulptor.file2url(filename)
    netfile = request.urlopen(url)
    mat = []
    for line in netfile.readlines():
        mini = []
        strline = line.decode('utf-8')
        strings = strline.split (", ")
        strings[-1] = strings[-1].replace("\r\n","")
        for entry in strings:
            mini.append(float(entry))
        mat.append(mini)    
    return numeric.Matrix(mat)


class LinearModel:
    """
    A class used to represent a Linear statistical
    model of multiple variables. This model takes
    a vector of input variables and predicts that
    the measured variable will be their weighted sum.
    """

    def __init__(self, weights):
        """
        Create a new LinearModel.

        inputs:
            - weights: an m x 1 matrix of weights
        """
        self._weights = weights

    def __str__(self):
        """
        Return: weights as a human readable string.
        """
        return str(self._weights)

    def get_weights(self):
        """
        Return: the weights associated with the model.
        """
        return self._weights

    def generate_predictions(self, inputs):
        """
        Use this model to predict a matrix of
        measured variables given a matrix of input data.

        inputs:
            - inputs: an n x m matrix of explanatory variables

        Returns: an n x 1 matrix of predictions
        """
       

        return inputs @ self.get_weights()

   

    def prediction_error(self, inputs, actual_result):
        """
        Calculate the MSE between the actual measured
        data and the predictions generated by this model
        based on the input data.

        inputs:
            - inputs: inputs: an n x m matrix of explanatory variables
            - actual_result: an n x 1 matrix of the corresponding
                             actual values for the measured variables

        Returns: a float that is the MSE between the generated
        data and the actual data
        """
        num_rows = inputs.shape()[0]
        weight = self.get_weights()
        x_matrix = inputs
        y_matrix = actual_result
        
        x_trans = x_matrix.transpose()
        y_trans = y_matrix.transpose()
        w_trans = weight.transpose()
        
        prod1 = w_trans@x_trans@x_matrix@weight
        prod2 = y_trans@x_matrix@weight
        prod3 = y_trans@y_matrix
        
        sum_var = prod1[(0,0)]-2*prod2[(0,0)]+prod3[(0,0)]
        return sum_var/num_rows
        
       
        
def fit_least_squares(input_data, output_data):
    """
    Create a Linear Model which predicts the output vector
    given the input matrix with minimal Mean-Squared Error.

    inputs:
        - input_data: an n x m matrix
        - output_data: an n x 1 matrix

    returns: a LinearModel object which has been fit to approximately
    match the data
    """
    
    weights = (input_data.transpose()@input_data).inverse()@(input_data.transpose())@output_data
    
    return LinearModel(weights)

def soft_threshold(x_var,t_var):
    """
    Moves the x_var closer to 0 by the distance t_var and returns new x_var value.
    
    inputs:
        -x_var: a float representing a value we want to move closer to 0
        -t_var: a float representing the size of distance x_var moves
    
    returns: a float representing the modified x_var
    
    """
    returned = 0
    if x_var>t_var:
        returned = x_var-t_var
    if abs(x_var) <= t_var:
        returned =  0
    if x_var<(-t_var):
        returned = x_var+t_var
    
    return returned

def fit_lasso(param, iterations, input_data, output_data):
    """
    Create a Linear Model which predicts the output vector
    given the input matrix using the LASSO method.

    inputs:
        - param: a float representing the lambda parameter
        - iterations: an integer representing the number of iterations
        - input_data: an n x m matrix
        - output_data: an n x 1 matrix

    returns: a LinearModel object which has been fit to approximately
    match the data
    """
    w_var = fit_least_squares(input_data, output_data).get_weights()
    i_var = 0
    x_trans_y = input_data.transpose()@output_data
    x_trans_x = input_data.transpose()@input_data
    while i_var < iterations:
        w_old = w_var.copy()
        for j_var in range(input_data.shape()[1]):
            a_j_difference = x_trans_y[(j_var,0)]-((x_trans_x.getrow(j_var)@w_var)[(0,0)])
            a_j = a_j_difference/x_trans_x[(j_var,j_var)]
            b_j = param/(2.0*(x_trans_x)[(j_var,j_var)])
            w_var[(j_var,0)] = soft_threshold(w_var[(j_var,0)]+a_j, b_j)
        
        sum_list = []
        for value in range(input_data.shape()[1]):
            sum_list.append(abs(w_var[(value,0)]-w_old[(value,0)]))
        list_sum = sum(sum_list)
         
        if list_sum < 10**(-5):
            break
        i_var+=1
        
    return LinearModel(w_var)

def run_experiment(iterations):
    """
    Using some historical data from 1954-2000, as
    training data, generate weights for a Linear Model
    using both the Least-Squares method and the
    LASSO method (with several different lambda values).

    Test each of these models using the historical
    data from 2001-2012 as test data.

    inputs:
        - iterations: an integer representing the number of iterations to use

    Print out the model's prediction error on the two data sets
    """
    
    #1954-2000 data
    mat_1954_x = read_matrix("comp140_analytics_baseball.txt")
    mat_1954_y = read_matrix("comp140_analytics_wins.txt")
    
    #2001-2012 data
    mat_2001_x = read_matrix("comp140_analytics_baseball_test.txt")
    mat_2001_y = read_matrix("comp140_analytics_wins_test.txt")
    
    
    #1954 least-squares estimation
    lse_model_1954 = fit_least_squares(mat_1954_x, mat_1954_y)
    
    #2001 least-squares estimation
    lse_error = lse_model_1954.prediction_error(mat_2001_x, mat_2001_y)
    
    #1954-2000 LASSO
    training_models_1954 = []
    training_models_1954.append(fit_lasso(1000, iterations, mat_1954_x, mat_1954_y))
    training_models_1954.append(fit_lasso(2000, iterations, mat_1954_x, mat_1954_y))
    training_models_1954.append(fit_lasso(3000, iterations, mat_1954_x, mat_1954_y))
    
    errors = []
    errors.append(training_models_1954[0].prediction_error(mat_2001_x, mat_2001_y))
    errors.append(training_models_1954[1].prediction_error(mat_2001_x, mat_2001_y))
    errors.append(training_models_1954[2].prediction_error(mat_2001_x, mat_2001_y))
    
    print("LASSO ERROR ON 2001 - 2012 DATA: lambda = 1000: " , errors[0])
    print("LASSO ERROR ON 2001 - 2012 DATA: lambda = 2000: " , errors[1])
    print("LASSO ERROR ON 2001 - 2012 DATA: lambda = 3000: " , errors[2])
    
    print("LSE ERROR ON 1954 - 2000 DATA: ", lse_error)
   # print("LASSO ERROR ON 2001 - 2012 DATA: ", LASSO_min_error)

run_experiment(2)    